{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d41edeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img, image_dataset_from_directory, ImageDataGenerator\n",
    "from keras import layers, regularizers\n",
    "from keras.layers import Input, Dense,GaussianNoise, Activation, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.regularizers import l2, l1_l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2712dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=255\n",
    "img_width=255\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaed0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './leaves_dataset'\n",
    "new_ds_path = path + '/new_leave_dataset'\n",
    "old_ds_path = path + '/Leaves'\n",
    "# df = pd.read_csv(path+'/leaves_final.csv')\n",
    "\n",
    "# if os.path.isdir(new_ds_path):\n",
    "#     shutil.rmtree(new_ds_path, ignore_errors=True)\n",
    "# os.mkdir(new_ds_path)\n",
    "# for index, row in df.iterrows():\n",
    "#     new_dir_path = os.path.join(new_ds_path, row['ScientificName'])\n",
    "#     if os.path.isdir(new_dir_path) is False:\n",
    "#         os.mkdir(new_dir_path)\n",
    "#     shutil.copy(os.path.join(old_ds_path,row['FileName']),new_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b606fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Osmanthus fragrans Lour.\n",
      "Found 56 images belonging to 1 classes.\n",
      "Found 112 images belonging to 1 classes.\n",
      "Mahonia bealei (Fortune) Carr.\n",
      "Found 55 images belonging to 1 classes.\n",
      "Found 110 images belonging to 1 classes.\n",
      "Chimonanthus praecox L.\n",
      "Found 52 images belonging to 1 classes.\n",
      "Found 104 images belonging to 1 classes.\n",
      "Tonna sinensis M. Roem.\n",
      "Found 65 images belonging to 1 classes.\n",
      "Found 125 images belonging to 1 classes.\n",
      "Lagerstroemia indica (L.) Pers.\n",
      "Found 61 images belonging to 1 classes.\n",
      "Found 121 images belonging to 1 classes.\n",
      "Aesculus chinensis\n",
      "Found 63 images belonging to 1 classes.\n",
      "Found 123 images belonging to 1 classes.\n",
      "Magnolia grandiflora L.\n",
      "Found 57 images belonging to 1 classes.\n",
      "Found 114 images belonging to 1 classes.\n",
      "Manglietia fordiana Oliv.\n",
      "Found 52 images belonging to 1 classes.\n",
      "Found 104 images belonging to 1 classes.\n",
      "Populus Ã—canadensis Moench\n",
      "Found 64 images belonging to 1 classes.\n",
      "Found 124 images belonging to 1 classes.\n",
      "Acer buergerianum Miq.\n",
      "Found 53 images belonging to 1 classes.\n",
      "Found 106 images belonging to 1 classes.\n",
      "Viburnum awabuki K.Koch\n",
      "Found 60 images belonging to 1 classes.\n",
      "Found 120 images belonging to 1 classes.\n",
      "Ginkgo biloba L.\n",
      "Found 62 images belonging to 1 classes.\n",
      "Found 122 images belonging to 1 classes.\n",
      "Liriodendron chinense (Hemsl.) Sarg.\n",
      "Found 53 images belonging to 1 classes.\n",
      "Found 106 images belonging to 1 classes.\n",
      "Acer Palmatum\n",
      "Found 56 images belonging to 1 classes.\n",
      "Found 112 images belonging to 1 classes.\n",
      "Nerium oleander L.\n",
      "Found 66 images belonging to 1 classes.\n",
      "Found 126 images belonging to 1 classes.\n",
      "Prunus persica (L.) Batsch\n",
      "Found 54 images belonging to 1 classes.\n",
      "Found 108 images belonging to 1 classes.\n",
      "Cercis chinensis\n",
      "Found 72 images belonging to 1 classes.\n",
      "Found 132 images belonging to 1 classes.\n",
      "Pittosporum tobira (Thunb.) Ait. f.\n",
      "Found 63 images belonging to 1 classes.\n",
      "Found 123 images belonging to 1 classes.\n",
      "Ligustrum lucidum Ait. f.\n",
      "Found 55 images belonging to 1 classes.\n",
      "Found 110 images belonging to 1 classes.\n",
      "Berberis anhweiensis Ahrendt\n",
      "Found 65 images belonging to 1 classes.\n",
      "Found 125 images belonging to 1 classes.\n",
      "Podocarpus macrophyllus (Thunb.) Sweet\n",
      "Found 60 images belonging to 1 classes.\n",
      "Found 120 images belonging to 1 classes.\n",
      "Cinnamomum japonicum Sieb.\n",
      "Found 55 images belonging to 1 classes.\n",
      "Found 110 images belonging to 1 classes.\n",
      "Indigofera tinctoria L.\n",
      "Found 73 images belonging to 1 classes.\n",
      "Found 133 images belonging to 1 classes.\n",
      "Ilex macrocarpa Oliv.\n",
      "Found 50 images belonging to 1 classes.\n",
      "Found 110 images belonging to 1 classes.\n",
      "Phyllostachys edulis (Carr.) Houz.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 118 images belonging to 1 classes.\n",
      "Prunus serrulata Lindl. var. lannesiana auct.\n",
      "Found 55 images belonging to 1 classes.\n",
      "Found 110 images belonging to 1 classes.\n",
      "Cedrus deodara (Roxb.) G. Don\n",
      "Found 77 images belonging to 1 classes.\n",
      "Found 137 images belonging to 1 classes.\n",
      "Citrus reticulata Blanco\n",
      "Found 56 images belonging to 1 classes.\n",
      "Found 112 images belonging to 1 classes.\n",
      "Koelreuteria paniculata Laxm.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 118 images belonging to 1 classes.\n",
      "Phoebe nanmu (Oliv.) Gamble\n",
      "Found 62 images belonging to 1 classes.\n",
      "Found 122 images belonging to 1 classes.\n",
      "Cinnamomum camphora (L.) J. Presl\n",
      "Found 65 images belonging to 1 classes.\n",
      "Found 125 images belonging to 1 classes.\n",
      "Kalopanax septemlobus (Thunb. ex A.Murr.) Koidz.\n",
      "Found 52 images belonging to 1 classes.\n",
      "Found 104 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# aug1_datagen = ImageDataGenerator(                               \n",
    "#     rotation_range=180,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     zoom_range=0.08,\n",
    "#     fill_mode='nearest',\n",
    "#     shear_range=0.08)\n",
    "\n",
    "# aug2_datagen = ImageDataGenerator(                               \n",
    "#     width_shift_range=[-50,50],\n",
    "#     height_shift_range=[-50,50]) \n",
    "\n",
    "\n",
    "# class_names=[]\n",
    "# for dirname in glob.iglob(new_ds_path +'/*',recursive=True):\n",
    "#     class_names.append(dirname.split('/')[-1])\n",
    "\n",
    "# for class_n in class_names:\n",
    "#     i=0\n",
    "#     print(class_n)\n",
    "\n",
    "#     for batch in aug1_datagen.flow_from_directory(new_ds_path,\n",
    "#                                 shuffle=False,\n",
    "#                                 target_size=(img_height, img_width),\n",
    "#                                 classes=[class_n],\n",
    "#                                 batch_size=10,\n",
    "#                                 save_prefix='aug',\n",
    "#                                 save_to_dir = new_ds_path+'/'+class_n,\n",
    "#                                 save_format='jpg'):\n",
    "\n",
    "#             i+=1\n",
    "#             if i > 5:\n",
    "#                 break\n",
    "    \n",
    "#     for batch in aug2_datagen.flow_from_directory(new_ds_path,\n",
    "#                                 shuffle=False,\n",
    "#                                 target_size=(img_height, img_width),\n",
    "#                                 classes=[class_n],\n",
    "#                                 batch_size=5,\n",
    "#                                 save_prefix='aug',\n",
    "#                                 save_to_dir = new_ds_path+'/'+class_n,\n",
    "#                                 save_format='jpg'):\n",
    "\n",
    "#             i+=1\n",
    "#             if i > 5:\n",
    "#                 break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416b5b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 3906 files [00:00, 21157.58 files/s]\n"
     ]
    }
   ],
   "source": [
    "# import splitfolders\n",
    "\n",
    "# splitfolders.ratio(new_ds_path, output=os.path.join(new_ds_path,'output'), move=True,\n",
    "#                     seed=1337, ratio=(0.8, 0.2)) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7916ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3114 images belonging to 32 classes.\n",
      "Found 792 images belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_folder = os.path.join(new_ds_path,'output','train')\n",
    "valid_folder = os.path.join(new_ds_path,'output','val')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255) \n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    seed = 42,\n",
    "    shuffle=True)\n",
    "\n",
    "valid_ds = train_datagen.flow_from_directory(\n",
    "    valid_folder,\n",
    "    color_mode=\"rgb\",    \n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    seed = 42,\n",
    "    shuffle=True) # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d4c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=list(train_ds.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34454e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 255, 255, 3)\n",
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ca8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = image_batch.shape[1]\n",
    "no_of_channel =image_batch.shape[3]\n",
    "input_shape = (image_size, image_size, no_of_channel)\n",
    "num_labels = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d218318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 19:46:56.409305: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 18s 0us/step\n",
      "94781440/94765736 [==============================] - 18s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,653,216\n",
      "Trainable params: 1,065,504\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "resnet_model = Sequential()\n",
    "\n",
    "pretrained = ResNet50(include_top=False,\n",
    "                input_shape=input_shape,\n",
    "                pooling='avg',\n",
    "                classes=num_labels,\n",
    "                weights='imagenet')\n",
    "\n",
    "for layer in pretrained.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "resnet_model.add(pretrained)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49379c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 19:49:19.565075: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24969600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 19:49:22.542332: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26158464 exceeds 10% of free system memory.\n",
      "2022-09-14 19:49:22.555146: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 134217728 exceeds 10% of free system memory.\n",
      "2022-09-14 19:49:22.854543: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 134217728 exceeds 10% of free system memory.\n",
      "2022-09-14 19:49:23.008650: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - ETA: 0s - loss: 3.3545 - accuracy: 0.0934\n",
      "Epoch 00001: val_loss improved from inf to 3.18820, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 457s 5s/step - loss: 3.3545 - accuracy: 0.0934 - val_loss: 3.1882 - val_accuracy: 0.1376\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.9475 - accuracy: 0.1946\n",
      "Epoch 00002: val_loss improved from 3.18820 to 2.90114, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 466s 5s/step - loss: 2.9475 - accuracy: 0.1946 - val_loss: 2.9011 - val_accuracy: 0.1705\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.6700 - accuracy: 0.2521\n",
      "Epoch 00003: val_loss improved from 2.90114 to 2.69632, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 452s 5s/step - loss: 2.6700 - accuracy: 0.2521 - val_loss: 2.6963 - val_accuracy: 0.2664\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.4579 - accuracy: 0.3067\n",
      "Epoch 00004: val_loss improved from 2.69632 to 2.48721, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 455s 5s/step - loss: 2.4579 - accuracy: 0.3067 - val_loss: 2.4872 - val_accuracy: 0.2967\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.2468 - accuracy: 0.3696\n",
      "Epoch 00005: val_loss improved from 2.48721 to 2.37030, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 452s 5s/step - loss: 2.2468 - accuracy: 0.3696 - val_loss: 2.3703 - val_accuracy: 0.3169\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.1187 - accuracy: 0.3960\n",
      "Epoch 00006: val_loss improved from 2.37030 to 2.22543, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 455s 5s/step - loss: 2.1187 - accuracy: 0.3960 - val_loss: 2.2254 - val_accuracy: 0.3434\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.0061 - accuracy: 0.4213\n",
      "Epoch 00007: val_loss improved from 2.22543 to 2.10408, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 479s 5s/step - loss: 2.0061 - accuracy: 0.4213 - val_loss: 2.1041 - val_accuracy: 0.4015\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.8995 - accuracy: 0.4451\n",
      "Epoch 00008: val_loss improved from 2.10408 to 2.07448, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 454s 5s/step - loss: 1.8995 - accuracy: 0.4451 - val_loss: 2.0745 - val_accuracy: 0.3914\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.8419 - accuracy: 0.4566\n",
      "Epoch 00009: val_loss improved from 2.07448 to 2.01504, saving model to leafclassification.h5\n",
      "98/98 [==============================] - 449s 5s/step - loss: 1.8419 - accuracy: 0.4566 - val_loss: 2.0150 - val_accuracy: 0.3990\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.7696 - accuracy: 0.4660"
     ]
    }
   ],
   "source": [
    "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "filepath = 'leafclassification.h5'\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, baseline=0.5)\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_loss',\n",
    "                             save_weights_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min', \n",
    "                             save_best_only=True)\n",
    "\n",
    "history = resnet_model.fit(train_ds, validation_data=valid_ds, epochs=20,callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43990d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.1, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label = 'validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0476f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
